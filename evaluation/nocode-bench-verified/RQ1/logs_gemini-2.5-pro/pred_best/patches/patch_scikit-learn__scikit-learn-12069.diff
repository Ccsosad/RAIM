diff --git a/sklearn/decomposition/_kernel_pca.py b/sklearn/decomposition/_kernel_pca.py
index 6f0266a..650ab21 100644
--- a/sklearn/decomposition/_kernel_pca.py
+++ b/sklearn/decomposition/_kernel_pca.py
@@ -1,3 +1,4 @@
+
 """Kernel Principal Components Analysis."""
 
 # Author: Mathieu Blondel <mathieu@mblondel.org>
@@ -8,7 +9,7 @@ from scipy import linalg
 from scipy.sparse.linalg import eigsh
 
 from ..utils._arpack import _init_arpack_v0
-from ..utils.extmath import svd_flip
+from ..utils.extmath import svd_flip, randomized_svd
 from ..utils.validation import check_is_fitted, _check_psd_eigenvalues
 from ..utils.deprecation import deprecated
 from ..exceptions import NotFittedError
@@ -59,10 +60,11 @@ class KernelPCA(TransformerMixin, BaseEstimator):
         Learn the inverse transform for non-precomputed kernels.
         (i.e. learn to find the pre-image of a point)
 
-    eigen_solver : {'auto', 'dense', 'arpack'}, default='auto'
+    eigen_solver : {'auto', 'dense', 'arpack', 'randomized'}, default='auto'
         Select eigensolver to use. If n_components is much less than
         the number of training samples, arpack may be more efficient
-        than the dense eigensolver.
+        than the dense eigensolver. `randomized` is generally faster when
+        `n_components` is much smaller than `n_samples`.
 
     tol : float, default=0
         Convergence tolerance for arpack.
@@ -80,8 +82,8 @@ class KernelPCA(TransformerMixin, BaseEstimator):
         with zero eigenvalues are removed regardless.
 
     random_state : int, RandomState instance or None, default=None
-        Used when ``eigen_solver`` == 'arpack'. Pass an int for reproducible
-        results across multiple function calls.
+        Used when ``eigen_solver`` == 'arpack' or 'randomized'. Pass an int for
+        reproducible results across multiple function calls.
         See :term:`Glossary <random_state>`.
 
         .. versionadded:: 0.18
@@ -205,6 +207,13 @@ class KernelPCA(TransformerMixin, BaseEstimator):
         else:
             eigen_solver = self.eigen_solver
 
+        if eigen_solver == 'randomized' and n_components >= K.shape[0]:
+            # fallback to dense solver when n_components is not specified
+            # and eigen_solver is 'randomized'.
+            # Also when n_components is greater than n_samples, which is
+            # not handled by randomized_svd.
+            eigen_solver = 'dense'
+
         if eigen_solver == 'dense':
             self.lambdas_, self.alphas_ = linalg.eigh(
                 K, eigvals=(K.shape[0] - n_components, K.shape[0] - 1))
@@ -215,6 +224,12 @@ class KernelPCA(TransformerMixin, BaseEstimator):
                                                 tol=self.tol,
                                                 maxiter=self.max_iter,
                                                 v0=v0)
+        elif eigen_solver == 'randomized':
+            # sign flip is handled by svd_flip later
+            U, S, _ = randomized_svd(K, n_components=n_components,
+                                     flip_sign=False,
+                                     random_state=self.random_state)
+            self.lambdas_, self.alphas_ = S, U
 
         # make sure that the eigenvalues are ok and fix numerical issues
         self.lambdas_ = _check_psd_eigenvalues(self.lambdas_,
@@ -388,4 +403,4 @@ class KernelPCA(TransformerMixin, BaseEstimator):
 
     def _more_tags(self):
         return {'preserves_dtype': [np.float64, np.float32],
-                'pairwise': self.kernel == 'precomputed'}
+                'pairwise': self.kernel == 'precomputed'}
