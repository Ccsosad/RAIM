diff --git a/sklearn/decomposition/_kernel_pca.py b/sklearn/decomposition/_kernel_pca.py
index 6f0266a..fd884d9 100644
--- a/sklearn/decomposition/_kernel_pca.py
+++ b/sklearn/decomposition/_kernel_pca.py
@@ -8,7 +8,7 @@ from scipy import linalg
 from scipy.sparse.linalg import eigsh
 
 from ..utils._arpack import _init_arpack_v0
-from ..utils.extmath import svd_flip
+from ..utils.extmath import svd_flip, randomized_svd
 from ..utils.validation import check_is_fitted, _check_psd_eigenvalues
 from ..utils.deprecation import deprecated
 from ..exceptions import NotFittedError
@@ -59,10 +59,10 @@ class KernelPCA(TransformerMixin, BaseEstimator):
         Learn the inverse transform for non-precomputed kernels.
         (i.e. learn to find the pre-image of a point)
 
-    eigen_solver : {'auto', 'dense', 'arpack'}, default='auto'
+    eigen_solver : {'auto', 'dense', 'arpack', 'randomized'}, default='auto'
         Select eigensolver to use. If n_components is much less than
-        the number of training samples, arpack may be more efficient
-        than the dense eigensolver.
+        the number of training samples, arpack or randomized may be more
+        efficient than the dense eigensolver.
 
     tol : float, default=0
         Convergence tolerance for arpack.
@@ -80,8 +80,8 @@ class KernelPCA(TransformerMixin, BaseEstimator):
         with zero eigenvalues are removed regardless.
 
     random_state : int, RandomState instance or None, default=None
-        Used when ``eigen_solver`` == 'arpack'. Pass an int for reproducible
-        results across multiple function calls.
+        Used when ``eigen_solver`` == 'arpack' or 'randomized'. Pass an int
+        for reproducible results across multiple function calls.
         See :term:`Glossary <random_state>`.
 
         .. versionadded:: 0.18
@@ -215,6 +215,19 @@ class KernelPCA(TransformerMixin, BaseEstimator):
                                                 tol=self.tol,
                                                 maxiter=self.max_iter,
                                                 v0=v0)
+        elif eigen_solver == 'randomized':
+            # Use randomized SVD to compute the top n_components eigenvectors
+            # Note: randomized_svd returns U, S, Vt. We need V (eigenvectors) and S^2 (eigenvalues)
+            # Since K is symmetric, U and V are the same.
+            n_components = min(n_components, K.shape[0] - 1)
+            U, S, _ = randomized_svd(K, n_components=n_components,
+                                     n_iter=3,  # default value as in PCA
+                                     random_state=self.random_state,
+                                     flip_sign=True)
+            self.lambdas_ = S ** 2
+            self.alphas_ = U
+        else:
+            raise ValueError("Unsupported eigen_solver '{}'".format(eigen_solver))
 
         # make sure that the eigenvalues are ok and fix numerical issues
         self.lambdas_ = _check_psd_eigenvalues(self.lambdas_,
@@ -388,4 +401,4 @@ class KernelPCA(TransformerMixin, BaseEstimator):
 
     def _more_tags(self):
         return {'preserves_dtype': [np.float64, np.float32],
-                'pairwise': self.kernel == 'precomputed'}
+                'pairwise': self.kernel == 'precomputed'}
diff --git a/benchmarks/bench_kernel_pca_solvers_time_vs_n_components.py b/benchmarks/bench_kernel_pca_solvers_time_vs_n_components.py
new file mode 100644
index 0000000..ea899d6
--- /dev/null
+++ b/benchmarks/bench_kernel_pca_solvers_time_vs_n_components.py
@@ -0,0 +1,42 @@
+"""
+Benchmark for Kernel PCA solvers with varying number of components.
+"""
+import numpy as np
+import time
+from sklearn.decomposition import KernelPCA
+from sklearn.datasets import make_circles
+
+def benchmark_kernel_pca_solvers():
+    n_samples = 1000
+    n_features = 50
+    n_components_range = [5, 10, 20, 30, 40, 50]
+    solvers = ['dense', 'arpack', 'randomized']
+    results = {solver: [] for solver in solvers}
+
+    X, _ = make_circles(n_samples=n_samples, noise=0.1, factor=0.5)
+    X = X + np.random.randn(n_samples, 2) * 0.1
+    # Use only the first n_features (pad if needed)
+    if X.shape[1] < n_features:
+        X = np.hstack([X, np.random.randn(n_samples, n_features - X.shape[1])])
+    else:
+        X = X[:, :n_features]
+
+    for n_components in n_components_range:
+        for solver in solvers:
+            if solver == 'arpack' and n_components >= n_samples:
+                continue
+            kpca = KernelPCA(n_components=n_components, kernel='rbf',
+                             eigen_solver=solver, random_state=42)
+            start = time.time()
+            kpca.fit(X)
+            elapsed = time.time() - start
+            results[solver].append(elapsed)
+            print(f"n_components={n_components}, solver={solver}, time={elapsed:.3f}s")
+
+    # Print results
+    print("\nResults:")
+    for solver in solvers:
+        print(f"{solver}: {results[solver]}")
+
+if __name__ == '__main__':
+    benchmark_kernel_pca_solvers()
diff --git a/benchmarks/bench_kernel_pca_solvers_time_vs_n_samples.py b/benchmarks/bench_kernel_pca_solvers_time_vs_n_samples.py
new file mode 100644
index 0000000..e108ed5
--- /dev/null
+++ b/benchmarks/bench_kernel_pca_solvers_time_vs_n_samples.py
@@ -0,0 +1,42 @@
+"""
+Benchmark for Kernel PCA solvers with varying number of samples.
+"""
+import numpy as np
+import time
+from sklearn.decomposition import KernelPCA
+from sklearn.datasets import make_circles
+
+def benchmark_kernel_pca_solvers():
+    n_components = 10
+    n_features = 20
+    n_samples_range = [100, 500, 1000, 2000, 3000]
+    solvers = ['dense', 'arpack', 'randomized']
+    results = {solver: [] for solver in solvers}
+
+    for n_samples in n_samples_range:
+        X, _ = make_circles(n_samples=n_samples, noise=0.1, factor=0.5)
+        X = X + np.random.randn(n_samples, 2) * 0.1
+        # Use only the first n_features (pad if needed)
+        if X.shape[1] < n_features:
+            X = np.hstack([X, np.random.randn(n_samples, n_features - X.shape[1])])
+        else:
+            X = X[:, :n_features]
+
+        for solver in solvers:
+            if solver == 'arpack' and n_components >= n_samples:
+                continue
+            kpca = KernelPCA(n_components=n_components, kernel='rbf',
+                             eigen_solver=solver, random_state=42)
+            start = time.time()
+            kpca.fit(X)
+            elapsed = time.time() - start
+            results[solver].append(elapsed)
+            print(f"n_samples={n_samples}, solver={solver}, time={elapsed:.3f}s")
+
+    # Print results
+    print("\nResults:")
+    for solver in solvers:
+        print(f"{solver}: {results[solver]}")
+
+if __name__ == '__main__':
+    benchmark_kernel_pca_solvers()
