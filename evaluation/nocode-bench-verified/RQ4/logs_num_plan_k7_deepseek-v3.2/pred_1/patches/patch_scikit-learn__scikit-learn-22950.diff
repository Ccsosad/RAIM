diff --git a/sklearn/linear_model/_ridge.py b/sklearn/linear_model/_ridge.py
index 793a339..e7d40d1 100644
--- a/sklearn/linear_model/_ridge.py
+++ b/sklearn/linear_model/_ridge.py
@@ -137,7 +137,35 @@ def _solve_sparse_cg(
     return coefs
 
 
-def _solve_lsqr(X, y, alpha, max_iter=None, tol=1e-3):
+def _solve_lsqr(
+    X,
+    y,
+    alpha,
+    max_iter=None,
+    tol=1e-3,
+    X_offset=None,
+    X_scale=None,
+    sample_weight_sqrt=None,
+):
+    if sample_weight_sqrt is None:
+        sample_weight_sqrt = np.ones(X.shape[0], dtype=X.dtype)
+
+    if X_offset is not None and X_scale is not None:
+        # Center the data
+        X_offset_scale = X_offset / X_scale
+
+        def matvec(b):
+            return X.dot(b) - sample_weight_sqrt * b.dot(X_offset_scale)
+
+        def rmatvec(b):
+            return X.T.dot(b) - X_offset_scale * b.dot(sample_weight_sqrt)
+
+        X1 = sparse.linalg.LinearOperator(
+            shape=X.shape, matvec=matvec, rmatvec=rmatvec, dtype=X.dtype
+        )
+    else:
+        X1 = sp_linalg.aslinearoperator(X)
+
     n_samples, n_features = X.shape
     coefs = np.empty((y.shape[1], n_features), dtype=X.dtype)
     n_iter = np.empty(y.shape[1], dtype=np.int32)
@@ -629,7 +657,16 @@ def _ridge_regression(
         )
 
     elif solver == "lsqr":
-        coef, n_iter = _solve_lsqr(X, y, alpha, max_iter, tol)
+        coef, n_iter = _solve_lsqr(
+            X,
+            y,
+            alpha,
+            max_iter,
+            tol,
+            X_offset=X_offset,
+            X_scale=X_scale,
+            sample_weight_sqrt=sample_weight_sqrt if has_sw else None,
+        )
 
     elif solver == "cholesky":
         if n_features > n_samples:
