diff --git a/sklearn/isotonic.py b/sklearn/isotonic.py
index 6d02e92..42f1abc 100644
--- a/sklearn/isotonic.py
+++ b/sklearn/isotonic.py
@@ -318,6 +318,11 @@ class IsotonicRegression(RegressorMixin, TransformerMixin, BaseEstimator):
         check_params = dict(accept_sparse=False, ensure_2d=False)
         X = check_array(X, dtype=[np.float64, np.float32], **check_params)
         y = check_array(y, dtype=X.dtype, **check_params)
+        # Allow 2d array with 1 feature
+        if X.ndim == 2 and X.shape[1] == 1:
+            X = X.flatten()
+        elif X.ndim != 1:
+            raise ValueError("X should be a 1d array or 2d array with a single feature")
         check_consistent_length(X, y, sample_weight)
 
         # Transform y by running the isotonic regression algorithm and
@@ -355,8 +360,11 @@ class IsotonicRegression(RegressorMixin, TransformerMixin, BaseEstimator):
 
         T = check_array(T, dtype=dtype, ensure_2d=False)
 
-        if len(T.shape) != 1:
-            raise ValueError("Isotonic regression input should be a 1d array")
+        # Allow 2d array with 1 feature
+        if T.ndim == 2 and T.shape[1] == 1:
+            T = T.flatten()
+        elif T.ndim != 1:
+            raise ValueError("Isotonic regression input should be a 1d array or 2d array with a single feature")
 
         # Handle the out_of_bounds argument by clipping if needed
         if self.out_of_bounds not in ["raise", "nan", "clip"]:
@@ -406,4 +414,4 @@ class IsotonicRegression(RegressorMixin, TransformerMixin, BaseEstimator):
             self._build_f(self.X_thresholds_, self.y_thresholds_)
 
     def _more_tags(self):
-        return {'X_types': ['1darray']}
+        return {'X_types': ['1darray']}
