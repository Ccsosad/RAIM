diff --git a/sklearn/linear_model/_ridge.py b/sklearn/linear_model/_ridge.py
index 793a339..dcafced 100644
--- a/sklearn/linear_model/_ridge.py
+++ b/sklearn/linear_model/_ridge.py
@@ -137,7 +137,7 @@ def _solve_sparse_cg(
     return coefs
 
 
-def _solve_lsqr(X, y, alpha, max_iter=None, tol=1e-3):
+def _solve_lsqr(X, y, alpha, max_iter=None, tol=1e-3, X_offset=None, X_scale=None, sample_weight_sqrt=None):
     n_samples, n_features = X.shape
     coefs = np.empty((y.shape[1], n_features), dtype=X.dtype)
     n_iter = np.empty(y.shape[1], dtype=np.int32)
@@ -145,6 +145,17 @@ def _solve_lsqr(X, y, alpha, max_iter=None, tol=1e-3):
     # According to the lsqr documentation, alpha = damp^2.
     sqrt_alpha = np.sqrt(alpha)
 
+    # Center the data if needed
+    if X_offset is not None:
+        # Adjust X and y for the intercept
+        X = X - X_offset
+        y = y - y.mean(axis=0)
+
+    # Apply sample weights if provided
+    if sample_weight_sqrt is not None:
+        X = X * sample_weight_sqrt[:, np.newaxis]
+        y = y * sample_weight_sqrt[:, np.newaxis]
+
     for i in range(y.shape[1]):
         y_column = y[:, i]
         info = sp_linalg.lsqr(
@@ -629,7 +640,16 @@ def _ridge_regression(
         )
 
     elif solver == "lsqr":
-        coef, n_iter = _solve_lsqr(X, y, alpha, max_iter, tol)
+        coef, n_iter = _solve_lsqr(
+            X,
+            y,
+            alpha,
+            max_iter,
+            tol,
+            X_offset=X_offset,
+            X_scale=X_scale,
+            sample_weight_sqrt=sample_weight_sqrt if has_sw else None,
+        )
 
     elif solver == "cholesky":
         if n_features > n_samples:
